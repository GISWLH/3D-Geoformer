{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from my_tools import make_embedding, unfold_func, miniEncoder, miniDecoder, fold_func\n",
    "\n",
    "\n",
    "class Geoformer(nn.Module):\n",
    "    def __init__(self, mypara):\n",
    "        super().__init__()\n",
    "        self.mypara = mypara\n",
    "        d_size = mypara.d_size\n",
    "        self.device = mypara.device\n",
    "        if self.mypara.needtauxy:\n",
    "            self.cube_dim = (\n",
    "                (mypara.input_channal + 2) * mypara.patch_size[0] * mypara.patch_size[1]\n",
    "            )\n",
    "        else:\n",
    "            self.cube_dim = (\n",
    "                mypara.input_channal * mypara.patch_size[0] * mypara.patch_size[1]\n",
    "            )\n",
    "        self.predictor_emb = make_embedding(\n",
    "            cube_dim=self.cube_dim,\n",
    "            d_size=d_size,\n",
    "            emb_spatial_size=mypara.emb_spatial_size,\n",
    "            max_len=mypara.input_length,\n",
    "            device=self.device,\n",
    "        )\n",
    "        self.predictand_emb = make_embedding(\n",
    "            cube_dim=self.cube_dim,\n",
    "            d_size=d_size,\n",
    "            emb_spatial_size=mypara.emb_spatial_size,\n",
    "            max_len=mypara.output_length,\n",
    "            device=self.device,\n",
    "        )\n",
    "        enc_layer = miniEncoder(\n",
    "            d_size, mypara.nheads, mypara.dim_feedforward, mypara.dropout\n",
    "        )\n",
    "        dec_layer = miniDecoder(\n",
    "            d_size, mypara.nheads, mypara.dim_feedforward, mypara.dropout\n",
    "        )\n",
    "        self.encoder = multi_enc_layer(\n",
    "            enc_layer=enc_layer, num_layers=mypara.num_encoder_layers\n",
    "        )\n",
    "        self.decoder = multi_dec_layer(\n",
    "            dec_layer=dec_layer, num_layers=mypara.num_decoder_layers\n",
    "        )\n",
    "        self.linear_output = nn.Linear(d_size, self.cube_dim)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        predictor,\n",
    "        predictand,\n",
    "        in_mask=None,\n",
    "        enout_mask=None,\n",
    "        train=True,\n",
    "        sv_ratio=0,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            predictor: (batch, lb, C, H, W)\n",
    "            predictand: (batch, pre_len, C, H, W)\n",
    "        Returns:\n",
    "            outvar_pred: (batch, pre_len, C, H, W)\n",
    "        \"\"\"\n",
    "        en_out = self.encode(predictor=predictor, in_mask=in_mask)\n",
    "        if train:\n",
    "            with torch.no_grad():\n",
    "                connect_inout = torch.cat(\n",
    "                    [predictor[:, -1:], predictand[:, :-1]], dim=1\n",
    "                )\n",
    "                out_mask = self.make_mask_matrix(connect_inout.size(1))\n",
    "                outvar_pred = self.decode(\n",
    "                    connect_inout,\n",
    "                    en_out,\n",
    "                    out_mask,\n",
    "                    enout_mask,\n",
    "                )\n",
    "            if sv_ratio > 1e-7:\n",
    "                supervise_mask = torch.bernoulli(\n",
    "                    sv_ratio\n",
    "                    * torch.ones(predictand.size(0), predictand.size(1) - 1, 1, 1, 1)\n",
    "                ).to(self.device)\n",
    "            else:\n",
    "                supervise_mask = 0\n",
    "            predictand = (\n",
    "                supervise_mask * predictand[:, :-1]\n",
    "                + (1 - supervise_mask) * outvar_pred[:, :-1]\n",
    "            )\n",
    "            predictand = torch.cat([predictor[:, -1:], predictand], dim=1)\n",
    "            # predicting\n",
    "            outvar_pred = self.decode(\n",
    "                predictand,\n",
    "                en_out,\n",
    "                out_mask,\n",
    "                enout_mask,\n",
    "            )\n",
    "        else:\n",
    "            assert predictand is None\n",
    "            predictand = predictor[:, -1:]\n",
    "            for t in range(self.mypara.output_length):\n",
    "                out_mask = self.make_mask_matrix(predictand.size(1))\n",
    "                outvar_pred = self.decode(\n",
    "                    predictand,\n",
    "                    en_out,\n",
    "                    out_mask,\n",
    "                    enout_mask,\n",
    "                )\n",
    "                predictand = torch.cat([predictand, outvar_pred[:, -1:]], dim=1)\n",
    "        return outvar_pred\n",
    "\n",
    "    def encode(self, predictor, in_mask):\n",
    "        \"\"\"\n",
    "        predictor: (B, lb, C, H, W)\n",
    "        en_out: (Batch, S, lb, d_size)\n",
    "        \"\"\"\n",
    "        lb = predictor.size(1)\n",
    "        predictor = unfold_func(predictor, self.mypara.patch_size)\n",
    "        predictor = predictor.reshape(predictor.size(0), lb, self.cube_dim, -1).permute(\n",
    "            0, 3, 1, 2\n",
    "        )\n",
    "        predictor = self.predictor_emb(predictor)\n",
    "        en_out = self.encoder(predictor, in_mask)\n",
    "        return en_out\n",
    "\n",
    "    def decode(self, predictand, en_out, out_mask, enout_mask):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            predictand: (B, pre_len, C, H, W)\n",
    "        output:\n",
    "            (B, pre_len, C, H, W)\n",
    "        \"\"\"\n",
    "        H, W = predictand.size()[-2:]\n",
    "        T = predictand.size(1)\n",
    "        predictand = unfold_func(predictand, self.mypara.patch_size)\n",
    "        predictand = predictand.reshape(\n",
    "            predictand.size(0), T, self.cube_dim, -1\n",
    "        ).permute(0, 3, 1, 2)\n",
    "        predictand = self.predictand_emb(predictand)\n",
    "        output = self.decoder(predictand, en_out, out_mask, enout_mask)\n",
    "        output = self.linear_output(output).permute(0, 2, 3, 1)\n",
    "        output = output.reshape(\n",
    "            predictand.size(0),\n",
    "            T,\n",
    "            self.cube_dim,\n",
    "            H // self.mypara.patch_size[0],\n",
    "            W // self.mypara.patch_size[1],\n",
    "        )\n",
    "        output = fold_func(\n",
    "            output, output_size=(H, W), kernel_size=self.mypara.patch_size\n",
    "        )\n",
    "        return output\n",
    "\n",
    "    def make_mask_matrix(self, sz: int):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 0).T\n",
    "        return mask.to(self.mypara.device)\n",
    "\n",
    "\n",
    "class multi_enc_layer(nn.Module):\n",
    "    def __init__(self, enc_layer, num_layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([enc_layer for _ in range(num_layers)])\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return x\n",
    "\n",
    "\n",
    "class multi_dec_layer(nn.Module):\n",
    "    def __init__(self, dec_layer, num_layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([dec_layer for _ in range(num_layers)])\n",
    "\n",
    "    def forward(self, x, en_out, out_mask, enout_mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, en_out, out_mask, enout_mask)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 3, 64, 64])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first embedded_space shape: torch.Size([1, 8, 1, 64])\n",
      "first x shape: torch.Size([1, 16200, 16, 64])\n",
      "x shape: torch.Size([1, 16200, 16, 64])\n",
      "pe_time shape: torch.Size([1, 1, 16, 64])\n",
      "embedded_space shape: torch.Size([1, 16200, 16, 64])\n",
      "first embedded_space shape: torch.Size([1, 8, 1, 64])\n",
      "first x shape: torch.Size([1, 16200, 1, 64])\n",
      "x shape: torch.Size([1, 16200, 1, 64])\n",
      "pe_time shape: torch.Size([1, 1, 1, 64])\n",
      "embedded_space shape: torch.Size([1, 16200, 1, 64])\n",
      "Output shape: torch.Size([1, 1, 8, 720, 1440])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 假设 mypara 是模型的超参数类或对象\n",
    "class MyPara:\n",
    "    def __init__(self):\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.input_channal = 8  # 输入通道数，例如 RGB 图像\n",
    "        self.patch_size = (8, 8)  # Patch 大小\n",
    "        self.d_size = 64  # 嵌入维度\n",
    "        self.emb_spatial_size = 8  # 空间嵌入大小\n",
    "        self.input_length = 16  # 输入时间步长\n",
    "        self.output_length = 1  # 输出时间步长\n",
    "        self.nheads = 2  # 多头注意力头数\n",
    "        self.dim_feedforward = 256  # 前馈网络维度\n",
    "        self.dropout = 0.1  # Dropout 概率\n",
    "        self.num_encoder_layers = 1  # 编码器层数\n",
    "        self.num_decoder_layers = 1  # 解码器层数\n",
    "        self.needtauxy = False  # 是否需要附加的时间和空间坐标信息\n",
    "\n",
    "# 初始化 mypara\n",
    "mypara = MyPara()\n",
    "\n",
    "# 初始化模型\n",
    "model = Geoformer(mypara).to(mypara.device)\n",
    "\n",
    "# 随机生成输入数据\n",
    "batch_size = 1\n",
    "channels = mypara.input_channal\n",
    "height, width = 721, 1440  # 假设输入图像大小\n",
    "patch_size = mypara.patch_size\n",
    "if height % patch_size[0] != 0 or width % patch_size[1] != 0:\n",
    "    height = (height // patch_size[0]) * patch_size[0]\n",
    "    width = (width // patch_size[1]) * patch_size[1]\n",
    "\n",
    "input_length = mypara.input_length\n",
    "output_length = mypara.output_length\n",
    "\n",
    "# 生成随机输入和目标\n",
    "predictor = torch.rand(batch_size, input_length, channels, height, width).to(mypara.device)\n",
    "predictand = torch.rand(batch_size, output_length, channels, height, width).to(mypara.device)\n",
    "\n",
    "# 推理测试\n",
    "model.eval()  # 设置模型为评估模式\n",
    "with torch.no_grad():\n",
    "    output = model(predictor, None, train=False)\n",
    "\n",
    "# 打印输出形状\n",
    "print(\"Output shape:\", output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data ok!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "input = np.load(\"E:/data/input_25_all.npy\")\n",
    "nsr = np.load(\"E:/data/nsr_25_all.npy\")\n",
    "print('load data ok!')\n",
    "nsr_expanded = nsr[:, np.newaxis, :, :]\n",
    "input_array = np.concatenate((input, nsr_expanded), axis=1)\n",
    "input_array = torch.tensor(input_array)\n",
    "mean_all = torch.tensor([[[[ 2.8679e+02]],\n",
    "                          [[ 1.0096e+05]],\n",
    "                          [[-5.3626e+06]],\n",
    "                          [[-5.1725e-02]],\n",
    "                          [[ 1.8698e-01]],\n",
    "                          [[ 5.4089e+04]],\n",
    "                          [[ 1.3745e+04]],\n",
    "                          [[ 1.1180e+07]]]])\n",
    "std_all = torch.tensor([[[[1.1627e+01]],\n",
    "                         [[1.0610e+03]],\n",
    "                         [[4.9920e+06]],\n",
    "                         [[3.8811e+00]],\n",
    "                         [[2.4887e+00]],\n",
    "                         [[3.2341e+03]],\n",
    "                         [[1.3297e+03]],\n",
    "                         [[7.8841e+06]]]])\n",
    "\n",
    "\n",
    "# 标准化数据\n",
    "normalized_data = (input_array - mean_all) / std_all\n",
    "normalized_data[:, 0, :, :] = torch.nan_to_num(normalized_data[:, 0, :, :], nan=0.0)\n",
    "torch.save(normalized_data, \"normalized_train.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
